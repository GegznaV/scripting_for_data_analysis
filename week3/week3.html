<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type = "text/css">
  
  body {
      font-family: serif;
      font-size: 1.1em;
      margin-top: 5%;
      margin-right: 10%;
      margin-bottom: 5%;
      margin-left: 10%;
  }
  
  h1, h2 {
      margin-top: 2em;
  }
  
  
  a:link {
      color: hotpink;
  }
  
  
  a:visited {
      color: hotpink;
  }
  
  
  a:hover {
      color: red;
  }
  
  
  a:active {
      color: red;
  }
  
  .right {
      float: right;
      padding: 2em;
  }
  
  </style>
</head>
<body>
<h1 id="week-3">Week 3</h1>
<h2 id="reading">Reading</h2>
<ul>
<li><p>The Split-Apply-Combine Strategy for data analysis, by guru Hadley Wickham -- a paper that introduces the ideas behind plyr -- <a href="http://vita.had.co.nz/papers/plyr.pdf" class="uri">http://vita.had.co.nz/papers/plyr.pdf</a></p></li>
<li><p>R for data science, particularly chapters 12 about tidy data and 21 about iteration, also by Hadley Wickham and Garrett Grolemund -- <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a>.</p></li>
<li><p>The R Inferno by Patrick Burns -- Tongue in cheek (?!) epic about the horrors of R; in particular chapters 1-4 -- <a href="http://www.burns-stat.com/documents/books/the-r-inferno/" class="uri">http://www.burns-stat.com/documents/books/the-r-inferno/</a></p></li>
<li><p>Program better for fun and profit -- <a href="https://inattentionalcoffee.wordpress.com/2017/01/13/program-better-for-fun-and-for-profit/" class="uri">https://inattentionalcoffee.wordpress.com/2017/01/13/program-better-for-fun-and-for-profit/</a></p></li>
</ul>
<h2 id="exercises">Exercises</h2>
<ul>
<li><p>Simulate 1000 values from a normal distribution with mean 2 and standard deviation 1. How many percent of the samples were less than 0 or greater than 4? Is this what you would expect from theory?</p></li>
<li><p>Instead, simulate 100 samples from the same distribution, and repeat the process 1000 times. (Hint: use <code>replicate</code> and set <code>simplify = FALSE</code> if you prefer working with a list rather than a matrix.) Use <code>plyr</code> and <code>mean</code> to get the mean for each replicate. Use the <code>quantile</code> function to get the 5% and 95% percentile of the means. Is this what you would expect from theory?</p></li>
<li><p>Let's simulate a simple analysis of variance (of some of my favourite things). Imagine that we have two categorical variables. Use <code>rep</code>and <code>c</code> to create a vector with 20 elements each of &quot;raindrops&quot;, &quot;roses&quot;, and &quot;whiskers&quot; to be variable x. Create a response variable y, which equals 1 plus 0.5 if x is &quot;raindrops&quot; and 1 if x is &quot;whiskers&quot;. Add random varition by adding 100 draws from a standard normal distribution (<code>rnorm(100)</code>). Put x and y into a data frame. Plot this data. Use <code>lm</code> and <code>drop1</code> to estimate coefficients and perform an F-test.</p></li>
<li><p>Package the above analysis in a function that does the simulation and one function that does the analysis. Let the simulation function take the number of samples in each group as a parameter. Then repeat the above analysis 1000 times. Use the results to estimate the power of design. (Hint: The p-value of the test is in a component of the object you get from <code>drop1</code>. Assuming that you have saved the output of <code>drop1</code> in a variable called &quot;drop&quot;, you can get it with: <code>drop$&quot;Pr(&gt;F)&quot;[2]</code>.) Try the same thing with 10 and 7 samples per group. What is the power then?</p></li>
<li><p>Make boxplots or jittered scatterplots showing a few few simulated datasets side by side. (Hint: use <code>facet_wrap</code>.)</p></li>
<li><p>Look back at the coin toss functions from Week 1. Reimplement the <code>sim_data</code> function, but use <code>rbinom</code> instead of <code>sample</code>. (Hint: Use a binomial distribution with a trial number of one and a probability of success 0.5.) Make it take the same parameter and return its results in the same way as the original function.</p></li>
</ul>
<h2 id="homework">Homework</h2>
<p>The third homework is much more open-ended than the previous ones. The task is to perform design analysis by simulation of a study (actual or hypothetical) that is of interest to you. You will simulate data, implement the analysis in R, apply it to many simulated datasets, and evaluate the results. The report should include conclusions and informative statistical graphics.</p>
<p>You should follow, more or less, the following steps:</p>
<ul>
<li><p>Pick a potential data analysis that you know and care about. It should be reasonably simple, so if you pick something from a research project of yours, you will likely have to simplify a bit. Maybe you can focus or just one comparison.</p></li>
<li><p>What kind of data have you got, or would you get? Invent a model that can simulate that kind of data. Feel free to simplify and make assumptions. For instance, if we were analyzing a linear regression problem, we would probably draw the errors from a normal distribution, even if that is an idealization.</p></li>
<li><p>Think especially about the parameter of the model that will determine how big an effect there is, and the parameters that determine the variation. In a linear model context, this would be the coefficient associated with some continuous or categorical predictor. Sometimes, it's not so easy to find reasonable estimates for effects and errors. Maybe you can find something in the literature, or from existing previous data?</p></li>
<li><p>Implement the analysis as you would with real data. A good thing about working with simulated data is that you can put them in a convenient form from the beginning. It will probably save you some file reading and data wranglig.</p></li>
<li><p>Replicate your simulation, so that it generates hundreds or thousands of simulated datasets. Then apply your analysis to each simulated dataset. Gather the results of the simulations, and format the data for conventient summarization and plotting.</p></li>
<li><p>Summarize the results. Does the analysis detect an effect when it should? How good is the estimate of the effect? Plot some of the simulated datasets to see what true effects would look like.</p></li>
<li><p>Modify your simulations to generate data without any effect. How often does your analysis incorrectly detect an effect? Plot some of the no-effects datasets, to form pictures of what noise looks like.</p></li>
</ul>
</body>
</html>
